<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Nutch学习记录：Injector | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="#Nutch学习记录：Injector 因为nutch是建立在Hadoop架构之上的，在以后的程序代码中使用了MapReduce算法和HDFS（分布式文件系统），所以建议先把这些方面基本的知识看一下，这样在看到nutch代码中一些MapReduce的配置操作时也能理解什么意思。">
<meta name="keywords" content="Nutch">
<meta property="og:type" content="article">
<meta property="og:title" content="Nutch学习记录：Injector">
<meta property="og:url" content="http://yoursite.com/2015/12/11/Nutch/Nutch学习记录：Injector/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="#Nutch学习记录：Injector 因为nutch是建立在Hadoop架构之上的，在以后的程序代码中使用了MapReduce算法和HDFS（分布式文件系统），所以建议先把这些方面基本的知识看一下，这样在看到nutch代码中一些MapReduce的配置操作时也能理解什么意思。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://oawztil0a.bkt.clouddn.com/Blog/Nutch/Nutch-injector.png">
<meta property="og:updated_time" content="2017-05-24T08:37:29.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Nutch学习记录：Injector">
<meta name="twitter:description" content="#Nutch学习记录：Injector 因为nutch是建立在Hadoop架构之上的，在以后的程序代码中使用了MapReduce算法和HDFS（分布式文件系统），所以建议先把这些方面基本的知识看一下，这样在看到nutch代码中一些MapReduce的配置操作时也能理解什么意思。">
<meta name="twitter:image" content="http://oawztil0a.bkt.clouddn.com/Blog/Nutch/Nutch-injector.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Nutch/Nutch学习记录：Injector" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/12/11/Nutch/Nutch学习记录：Injector/" class="article-date">
  <time datetime="2015-12-11T02:08:15.000Z" itemprop="datePublished">2015-12-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Nutch/">Nutch</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Nutch学习记录：Injector
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>#Nutch学习记录：Injector</p>
<p>因为nutch是建立在Hadoop架构之上的，在以后的程序代码中使用了MapReduce算法和HDFS（分布式文件系统），所以建议先把这些方面基本的知识看一下，这样在看到nutch代码中一些MapReduce的配置操作时也能理解什么意思。<br><a id="more"></a><br>我们看到在Crawl类的处理代码中，最先执行了下面的一句：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">injector.inject(crawlDb, rootUrlDir);</span><br></pre></td></tr></table></figure></p>
<p>这一句调用的就是Injector类的inject()函数，目的是初始化抓取工作。Nutch的爬行初始的url来源主要有两个地方，首先是urls/urls.txt这个文件，我们可以在里面指定一些url；另一个是Nutch的爬行数据库crawldb（当然第一次爬行是没有的，第一次必须在utls.txt中指定url）。每次爬行的初始化工作就是将这两个地方的url合并。</p>
<p>Injector类做的事情主要归纳如下：</p>
<ul>
<li>对urls/urls.txt中的初始url进行规格化和过滤，并将结果存入临时目录下。</li>
<li>将上述结果与老的数据库（crawldb/current）合并，产生一个新的爬行数据库，并替换老的数据库current。</li>
</ul>
<h2 id="第一次MapReduce任务"><a href="#第一次MapReduce任务" class="headerlink" title="第一次MapReduce任务"></a>第一次MapReduce任务</h2><p>我们从inject()这个入口函数看起，看代码时忽略一些提示信息的输出等无关紧要的代码，只看一些重点部分。首先建立一个临时目录tempDir，用于第一次MapReduce任务的输出目录。接下来建立了第一个MapReduce任务，并做了相应配置如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">JobConf sortJob = <span class="keyword">new</span> NutchJob(getConf());  <span class="comment">// 建立一个MapReduce任务sortJob</span></span><br><span class="line">sortJob.setJobName(<span class="string">"inject "</span> + urlDir);</span><br><span class="line">FileInputFormat.addInputPath(sortJob, urlDir);  <span class="comment">// 为该任务的指定输入文件的路径</span></span><br><span class="line">sortJob.setMapperClass(InjectMapper.class);  <span class="comment">// 指定Mapper类</span></span><br><span class="line">FileOutputFormat.setOutputPath(sortJob, tempDir);  <span class="comment">// 任务的输出路径为刚才建立的临时目录</span></span><br><span class="line">sortJob.setOutputFormat(SequenceFileOutputFormat.class);  <span class="comment">// 指定输出格式</span></span><br><span class="line">sortJob.setOutputKeyClass(Text.class);  <span class="comment">// 指定输出的键的类型</span></span><br><span class="line">sortJob.setOutputValueClass(CrawlDatum.class);  <span class="comment">// 指定输出的值的类型</span></span><br><span class="line">sortJob.setLong(<span class="string">"injector.current.time"</span>, System.currentTimeMillis());</span><br><span class="line">JobClient.runJob(sortJob);  <span class="comment">// 启动任务</span></span><br></pre></td></tr></table></figure></p>
<p> 以上主要是MapReduce配置方面的知识，重申一遍：应该先找这方面的文章大体了解一下。MapReduce的核心思想是：把整个任务流程分为Map阶段和Reduce阶段，分别由Mapper的具体实现（如这里是InjectMapper类）和Reducer的具体实现来执行相关操作。操作分别定义在Mapper的map()函数和Reducer的reduce()函数中。其中map()函数接受一个key/value（键/值对）值作为输入，然后产生一个中间的key/value值的集合。之后MapReduce框架自动把具有相同key的key/value值的value几种到一起，交给reduce()函数处理。</p>
<p><strong>MapReduce任务的主要配置如下：</strong><br><code>FileInputFormat.addInputPath(任务, 路径);</code>用于指定输入路径，比如上面指定的输入路径就是urls/，里面有我们事先建立的urls.txt文件，Hadoop框架会自动读取其中的内容分配给各个Mapper。<br><code>FileOutputFormat.setOutputPath(任务, 路径);</code>指定任务的输出路径<br><code>任务.setMapperClass(类名);</code>指定Mapper，我们自定义一个类，继承Mapper接口并、实现其中的map()方法后，就可以作为一个Mapper。<br><code>任务.setReducerClass(类名);</code>指定Reducer，我们自定义一个类，继承Reducer接口并、实现其中的reduce()方法后，就可以作为一个Reducer。（Mapper和Reducer并不是必须指定的，就像上面这个任务就只有Mapper，没有Reducer）<br><code>任务.setOutputKeyClass(类型);</code>指定输出key/value对的key的类型，上面类型Text是Hadoop中定义的类，存放的是url。<br><code>任务.setOutputValueClass(类型);</code>指定输出key/value对的value的类型，上面类型CrawlDatum是Nutch定义的类，用于存放url的状态信息。</p>
<p>配置MapReduce后，通过JobClient.runJob()方法启动任务，之后任务的处理便有Mapper和Reducer来依次执行。我们先看Mapper——InjectMapper类。</p>
<h3 id="InjectMapper"><a href="#InjectMapper" class="headerlink" title="InjectMapper"></a>InjectMapper</h3><p>在查看map()函数之前，我们先来看一下configure()函数，这个函数用于获取一些后面用到的配置信息。这些配置信息是由Hadoop的Configuration类加载并传递过来的，加载的文件除了Hadoop本身的一些必须配置之外，与Nutch有关的配置主要存放在nutch-site.xml,nutch-default.xml,nutch-tool.xml这三个文件，获取的参数可以在其中查找，里面有关于该参数的详细描述。（这方面前一篇文章有提到）<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(JobConf job)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.jobConf = job;</span><br><span class="line">   urlNormalizers = <span class="keyword">new</span></span><br><span class="line">               URLNormalizers(job,URLNormalizers.SCOPE_INJECT);  <span class="comment">// 得到url规格化器，使url的表达正规化，操作依据在conf目录下的相关配置文件中</span></span><br><span class="line">    interval = jobConf.getInt(<span class="string">"db.fetch.interval.default"</span>, <span class="number">2592000</span>);  <span class="comment">// 获取参数：抓取时间间隔，默认30天</span></span><br><span class="line">    filters = <span class="keyword">new</span> URLFilters(jobConf);  <span class="comment">// 获取url过滤器，比如过滤掉ftp：开头的url、以.gif结尾的url等等，具体规则见相关配置文件</span></span><br><span class="line">    scfilters = <span class="keyword">new</span> ScoringFilters(jobConf);  <span class="comment">// 得到分数过滤器，用于抓取过程中url的得分计算</span></span><br><span class="line">    scoreInjected = jobConf.getFloat(<span class="string">"db.score.injected"</span>, <span class="number">1.0f</span>);  <span class="comment">// 获取参数：新加入的url的初始得分</span></span><br><span class="line">	curTime = job.getLong(<span class="string">"injector.current.time"</span>, System.currentTimeMillis());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>接下来进入map()函数，urls/urls.txt文件中存放我们初始想要注入的url，每个url占据一行，在url后面可以自己指定一些参数。该函数主要是对urls/urls.txt文件中的url进行规格化和过滤，并给它分配一个初始得分，此外若urls.txt文件中的url有指定的参数，则记录下来。</p>
<p>该函数的输入的key/value数据中的key是每个url在文件中的偏移量，value是url本身，这种包装是Hadoop框架自动做好的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(WritableComparable key, Text value, OutputCollector&lt;Text, CrawlDatum&gt; output, Reporter reporter)</span></span></span><br><span class="line"><span class="function">              <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">     String url = value.toString(); <span class="comment">// 得到url</span></span><br><span class="line">     <span class="keyword">if</span> (url != <span class="keyword">null</span> &amp;&amp; url.trim().startsWith(<span class="string">"#"</span>)) &#123;  <span class="comment">// 忽略文件中以“#”开始的行</span></span><br><span class="line">       <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">	 <span class="comment">//如果想指定元信息，则这些元信息必须用\t分隔，并用name=value形式指定</span></span><br><span class="line">    <span class="keyword">float</span> customScore = -<span class="number">1f</span>;</span><br><span class="line">    <span class="keyword">int</span> customInterval = interval;</span><br><span class="line">    Map&lt;String, String&gt; metadata = <span class="keyword">new</span> TreeMap&lt;String, String&gt;();  <span class="comment">// 如果有元信息，用于存储元信息（即文件中每一行的url后面跟着指定的信息，可以不指定）</span></span><br><span class="line">    <span class="keyword">if</span> (url.indexOf(<span class="string">"\t"</span>) != -<span class="number">1</span>) &#123;  <span class="comment">// 有元信息，则对这些元信息处理</span></span><br><span class="line">       String[] splits = url.split(<span class="string">"\t"</span>);</span><br><span class="line">       url = splits[<span class="number">0</span>];</span><br><span class="line">       <span class="keyword">for</span> (<span class="keyword">int</span> s = <span class="number">1</span>; s &lt; splits.length; s++) &#123;</span><br><span class="line">           <span class="keyword">int</span> indexEquals = splits[s].indexOf(<span class="string">"="</span>);</span><br><span class="line">           <span class="keyword">if</span> (indexEquals == -<span class="number">1</span>) &#123;</span><br><span class="line">              <span class="keyword">continue</span>;</span><br><span class="line">           &#125;</span><br><span class="line">           String metaname = splits[s].substring(<span class="number">0</span>, indexEquals);</span><br><span class="line">           String metavalue = splits[s].substring(indexEquals + <span class="number">1</span>);</span><br><span class="line">           <span class="keyword">if</span> (metaname.equals(nutchScoreMDName)) &#123; <span class="comment">//若是保留的元信息，直接记录下来使用，其它的先存储起来</span></span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                  customScore = Float.parseFloat(metavalue);</span><br><span class="line">              &#125; <span class="keyword">catch</span> (NumberFormatException nfe) &#123;</span><br><span class="line">              &#125;</span><br><span class="line">           &#125; <span class="keyword">else</span> <span class="keyword">if</span> (metaname.equals(nutchFetchIntervalMDName)) &#123;</span><br><span class="line">              <span class="keyword">try</span> &#123;</span><br><span class="line">                  customInterval = Integer.parseInt(metavalue);</span><br><span class="line">              &#125; <span class="keyword">catch</span> (NumberFormatException nfe) &#123;</span><br><span class="line">              &#125;</span><br><span class="line">           &#125; <span class="keyword">else</span></span><br><span class="line">              metadata.put(metaname, metavalue);</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">       url = urlNormalizers.normalize(url, URLNormalizers.SCOPE_INJECT);  <span class="comment">// 规格化url</span></span><br><span class="line">       url = filters.filter(url); <span class="comment">// 过滤url</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">       <span class="keyword">if</span> (LOG.isWarnEnabled()) &#123;</span><br><span class="line">           LOG.warn(<span class="string">"Skipping "</span> + url + <span class="string">":"</span> + e);</span><br><span class="line">       &#125;</span><br><span class="line">       url = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (url != <span class="keyword">null</span>) &#123; <span class="comment">// 如果url没有被过滤掉</span></span><br><span class="line">       value.set(url);</span><br><span class="line">       CrawlDatum datum = <span class="keyword">new</span> CrawlDatum(CrawlDatum.STATUS_INJECTED, customInterval);  <span class="comment">// 为它构造一个CrawlDatum对象，记录相应的状态</span></span><br><span class="line">       datum.setFetchTime(curTime);  <span class="comment">// 加入“fetchTime”信息（这里其实没用，并非真实的抓取时间）</span></span><br><span class="line">       <span class="comment">// 将元信息（若有）加入CrawlDatum中</span></span><br><span class="line">       Iterator&lt;String&gt; keysIter = metadata.keySet().iterator();</span><br><span class="line">       <span class="keyword">while</span> (keysIter.hasNext()) &#123;</span><br><span class="line">           String keymd = keysIter.next();</span><br><span class="line">           String valuemd = metadata.get(keymd);</span><br><span class="line">           datum.getMetaData().put(<span class="keyword">new</span> Text(keymd), <span class="keyword">new</span> Text(valuemd));</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">// 若知道了分数元信息，则将它加入CrawlDatum；否则将从配置文件中获得的初始得分信息加入</span></span><br><span class="line">       <span class="keyword">if</span> (customScore != -<span class="number">1</span>)</span><br><span class="line">           datum.setScore(customScore);</span><br><span class="line">       <span class="keyword">else</span></span><br><span class="line">           datum.setScore(scoreInjected);</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           scfilters.injectedScore(value, datum);  <span class="comment">// 对得分过滤</span></span><br><span class="line">       &#125; <span class="keyword">catch</span> (ScoringFilterException e) &#123;</span><br><span class="line">           <span class="keyword">if</span> (LOG.isWarnEnabled()) &#123;</span><br><span class="line">              LOG.warn(<span class="string">"Cannot filter injected score for url "</span> + url + <span class="string">", using default ("</span> + e.getMessage() + <span class="string">")"</span>);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       output.collect(value, datum);  <span class="comment">// 收集数据，key是url，value是描述该url状态信息的CrawlDatum</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>CrawlDatum是用于记录url的信息，其中一个很重要的信息是当前url的status（状态），在上面代码中，status是CrawlDatum.STATUS_INJECTED，表示是新注入的，在以后各个阶段会有相应的status。</p>
<p>再说一点：Nutch在爬行过程中并不是随机选择页面爬行，而是会根据“重要程度”，因此会对各个待爬行url打分，做这个工作的就是上面代码中的scfilters对象，它实际上用到的是一个插件，位于plugins/scoring-opic目录下，类是OPICScoringFilter。在以后爬行的许多阶段，都会调用其中的方法对url进行打分。其中使用的算法是OPIC算法，其主要思想是：“每个页面有一个初始得分，爬行过程中每个页面会把自己的得分平均分配给它的链接”。可以看一下源代码。</p>
<p>该MapReduce任务只有Mapper，没有Reducer，因此到此第一次MapReduce任务就结束了。收集的是&lt;url，CrawlDatum&gt;数据，存放在临时目录中。</p>
<h2 id="第二次MapReduce任务"><a href="#第二次MapReduce任务" class="headerlink" title="第二次MapReduce任务"></a>第二次MapReduce任务</h2><p>接下来又创建了一个MapReduce任务，用于将刚才临时目录里的数据与爬行数据库中的原有数据合并。如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">JobConf mergeJob = CrawlDb.createJob(getConf(), crawlDb);  <span class="comment">// 在CrawlDb类的createJob()里建立一个MapReduce任务</span></span><br><span class="line">FileInputFormat.addInputPath(mergeJob, tempDir);  <span class="comment">// 输入路径是上一次MapReduce产生的临时目录</span></span><br><span class="line">mergeJob.setReducerClass(InjectReducer.class); <span class="comment">// 设置Reducer，这个会替换之前设置的</span></span><br><span class="line">JobClient.runJob(mergeJob);  <span class="comment">// 启动任务</span></span><br></pre></td></tr></table></figure></p>
<p>可以看到，这个任务是通过调用CrawlDb类的createJob()函数创建的，我们进入这个函数看一下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> JobConf <span class="title">createJob</span><span class="params">(Configuration config, Path crawlDb)</span></span></span><br><span class="line"><span class="function">           <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Path newCrawlDb = <span class="keyword">new</span> Path(crawlDb, Integer.toString(<span class="keyword">new</span> Random().nextInt(Integer.MAX_VALUE)));  <span class="comment">// 建立一个临时目录newCrawlDb</span></span><br><span class="line">    JobConf job = <span class="keyword">new</span> NutchJob(config);  <span class="comment">//  建立一个MapReduce任务</span></span><br><span class="line">    job.setJobName(<span class="string">"crawldb "</span> + crawlDb);</span><br><span class="line">	Path current = <span class="keyword">new</span> Path(crawlDb, CURRENT_NAME);</span><br><span class="line">    <span class="keyword">if</span> (FileSystem.get(job).exists(current)) &#123;</span><br><span class="line">       FileInputFormat.addInputPath(job, current); <span class="comment">//将crwaldb/current目录（老爬行数据库）作为输入</span></span><br><span class="line">    &#125;</span><br><span class="line">    job.setInputFormat(SequenceFileInputFormat.class);  <span class="comment">// 指定输入格式：读取基于Hadoop的二进制文件，这个格式可加快读数据速度</span></span><br><span class="line">	job.setMapperClass(CrawlDbFilter.class);  <span class="comment">// 指定Mapper</span></span><br><span class="line">    job.setReducerClass(CrawlDbReducer.class);  <span class="comment">// 指定Reducer</span></span><br><span class="line">	FileOutputFormat.setOutputPath(job, newCrawlDb);  <span class="comment">// 指定输出路径是临时目录newCrawlDb</span></span><br><span class="line">    job.setOutputFormat(MapFileOutputFormat.class);  <span class="comment">// Hadoop中定义的一种部分使用索引键的格式</span></span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(CrawlDatum.class);</span><br><span class="line"> </span><br><span class="line">	<span class="keyword">return</span> job;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看出：在该函数中建立了一个MapReduce任务，并进行了相应的配置。这里有几点需要注意：</p>
<ol>
<li>MapReduce任务可以指定多个输入路径，例如这里在createJob()函数里指定了输入路径是crawldb/current目录，即老的爬行数据库；在外面inject()函数中又指定了tempDir，（即上次任务的输出）作为输入路径，这样才能对老url与新注入的url进行合并。</li>
<li>可能你会发现在createJob()函数里制定了Reducer为CrawlDbReducer类，在外面又指定了Reducer为InjectReducer类。这里要说明的是Reducer只能有一个，后面指定的Reducer类会覆盖前面指定的，也就是该任务的Reducer是InjectReducer类。</li>
</ol>
<p>接下来我们进入Mapper和Reducer去看看实际做了什么。</p>
<h3 id="CrawlDbFilter"><a href="#CrawlDbFilter" class="headerlink" title="CrawlDbFilter"></a>CrawlDbFilter</h3><p>我们发现该类的map()函数很简单，只是又做了一次规格化和过滤。</p>
<h3 id="InjectReducer"><a href="#InjectReducer" class="headerlink" title="InjectReducer"></a>InjectReducer</h3><p>前面讲过了MapReduce机制，map之后，会将具有共同key的value集中到一起。因此加入原先的数据库中（crawldb/current）有一个<a href="http://www.baidu.com，新注入的url里也有一个www.baidu.com，当然它们各自对应一个CrawlDatum，里面存储的状态等信息也不同。在reduce阶段处理的时候上面两个数据因为key（即url）相同，所以该key对应的两个value（两个CrawlDatum对象）会集中在一起处理。" target="_blank" rel="noopener">www.baidu.com，新注入的url里也有一个www.baidu.com，当然它们各自对应一个CrawlDatum，里面存储的状态等信息也不同。在reduce阶段处理的时候上面两个数据因为key（即url）相同，所以该key对应的两个value（两个CrawlDatum对象）会集中在一起处理。</a></p>
<p><strong>处理策略如下：</strong></p>
<ul>
<li>若一个key只对应一个CrawlDatum，并且其status是CrawlDatum.STATUS_INJECTED，表示是新注入的url信息，则将其状态更改为CrawlDatum.STATUS_DB_UNFETCHED，表示该url待抓取。</li>
<li>若一个key只对应一个CrawlDatum，并且其status不是CrawlDatum.STATUS_INJECTED，表示是老数据库中的url信息，直接收集。</li>
<li>若一个key对应两个CrawlDatum，则优先收集老数据库中的CrawlDatum。原因很简单，同一个url，老数据库中的CrawlDatum存储的信息肯定比新的CrawlDatum信息多，比如上次抓取时间并以此来判断当前是不是应该执行抓取等。</li>
</ul>
<p>下面看代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterator&lt;CrawlDatum&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">                       OutputCollector&lt;Text, CrawlDatum&gt; output, Reporter reporter)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">	<span class="keyword">boolean</span> oldSet = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">while</span> (values.hasNext()) &#123;  <span class="comment">// 一个key可能对于多个value</span></span><br><span class="line">        CrawlDatum val = values.next();</span><br><span class="line">        <span class="keyword">if</span> (val.getStatus() == CrawlDatum.STATUS_INJECTED) &#123;  <span class="comment">// 是新注入的url信息</span></span><br><span class="line">            injected.set(val);</span><br><span class="line">            injected.setStatus(CrawlDatum.STATUS_DB_UNFETCHED);  <span class="comment">//将新注入的状态改为STATUS_DB_UNFETCHED（待抓取）</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;  <span class="comment">// 是老数据库中的url信息</span></span><br><span class="line">            old.set(val);</span><br><span class="line">            oldSet = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    CrawlDatum res = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">if</span> (oldSet) res = old; <span class="comment">// 不覆盖原有值，即优先收集老数据库中的url信息</span></span><br><span class="line">    <span class="keyword">else</span> res = injected;</span><br><span class="line">	output.collect(key, res);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这个MapReduce也执行完了，接下来回到inject()函数继续向下执行，如下：</p>
<p><code>CrawlDb.install(mergeJob, crawlDb);</code></p>
<p>第二个MapReduce任务的输出（即合并后的爬行数据库）的目录是第二个临时目录newCrawlDb，我们需要把它替代current作为新的爬行数据库。代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">install</span><span class="params">(JobConf job, Path crawlDb)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Path newCrawlDb = FileOutputFormat.getOutputPath(job);  <span class="comment">// 得到上次的输出，即newCrawlDb目录</span></span><br><span class="line">    FileSystem fs = <span class="keyword">new</span> JobClient(job).getFs();</span><br><span class="line">    Path old = <span class="keyword">new</span> Path(crawlDb, <span class="string">"old"</span>);</span><br><span class="line">    Path current = <span class="keyword">new</span> Path(crawlDb, CURRENT_NAME);  <span class="comment">// 即crawldb/current目录</span></span><br><span class="line">    <span class="keyword">if</span> (fs.exists(current)) &#123;</span><br><span class="line">       <span class="keyword">if</span> (fs.exists(old))</span><br><span class="line">           fs.delete(old, <span class="keyword">true</span>);</span><br><span class="line">       fs.rename(current, old);  <span class="comment">// 将crawldb/current重命名为old</span></span><br><span class="line">    &#125;</span><br><span class="line">    fs.mkdirs(crawlDb);  <span class="comment">// 重新建立crawldb目录</span></span><br><span class="line">    fs.rename(newCrawlDb, current);  <span class="comment">// 因为newCrawlDb是建立下crawldb下的，直接重命名为current</span></span><br><span class="line">    <span class="keyword">if</span> (fs.exists(old))</span><br><span class="line">       fs.delete(old, <span class="keyword">true</span>);  <span class="comment">// 删除old</span></span><br><span class="line">    Path lock = <span class="keyword">new</span> Path(crawlDb, LOCK_NAME);</span><br><span class="line">    LockUtil.removeLockFile(fs, lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>接下来，是删除第一个临时目录tempDir，<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FileSystem fs = FileSystem.get(getConf());</span><br><span class="line">fs.delete(tempDir, <span class="keyword">true</span>);</span><br></pre></td></tr></table></figure></p>
<p>OK！Injector阶段结束了!我们回到Crawl类发现接下来进入一个循环，循环中首先调用了如下一行代码：<br>Path[] segs = generator.generate(crawlDb, segments, -1, topN, System.currentTimeMillis());<br>这行代码就根据Injector阶段得到的爬行数据库从中选出一部分url等待抓取。具体的操作在下一篇文章中分析。</p>
<p>该阶段数据处理的流程图如下：<br><img src="http://oawztil0a.bkt.clouddn.com/Blog/Nutch/Nutch-injector.png" alt></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/12/11/Nutch/Nutch学习记录：Injector/" data-id="cjtf6o95p00bj0fc5slf6stwx" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Nutch/">Nutch</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/12/17/Nutch/Nutch学习记录：Generator/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Nutch学习记录：Generator
        
      </div>
    </a>
  
  
    <a href="/2015/11/28/Nutch/Nutch学习记录：Nutch总体架构/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Nutch学习记录：Nutch总体架构</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/FreeMarker/">FreeMarker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Geek/">Geek</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java/">Java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Job/">Job</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Lucene/">Lucene</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MapReduce/">MapReduce</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nutch/">Nutch</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Project/">Project</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Scala/">Scala</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Scheme/">Scheme</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kafka/">kafka</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/信息检索/">信息检索</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/健身/">健身</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/操作系统/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/王道学习记录/">王道学习记录</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/网络/">网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FreeMarker/">FreeMarker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Geek/">Geek</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lucene/">Lucene</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MapReduce/">MapReduce</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Maven/">Maven</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NIO/">NIO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nutch/">Nutch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Project/">Project</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scala/">Scala</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scheme/">Scheme</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/">kafka</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/信息检索/">信息检索</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/健身/">健身</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/多线程/">多线程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/排序算法/">排序算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/操作系统/">操作系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据库/">数据库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据结构/">数据结构</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/框架/">框架</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/王道学习记录/">王道学习记录</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编程题/">编程题</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络/">网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面经/">面经</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面试笔记/">面试笔记</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 17px;">Algorithm</a> <a href="/tags/FreeMarker/" style="font-size: 11px;">FreeMarker</a> <a href="/tags/Geek/" style="font-size: 15px;">Geek</a> <a href="/tags/Java/" style="font-size: 20px;">Java</a> <a href="/tags/Linux/" style="font-size: 12px;">Linux</a> <a href="/tags/Lucene/" style="font-size: 11px;">Lucene</a> <a href="/tags/MapReduce/" style="font-size: 14px;">MapReduce</a> <a href="/tags/Maven/" style="font-size: 10px;">Maven</a> <a href="/tags/NIO/" style="font-size: 11px;">NIO</a> <a href="/tags/Nutch/" style="font-size: 19px;">Nutch</a> <a href="/tags/Project/" style="font-size: 11px;">Project</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Scala/" style="font-size: 11px;">Scala</a> <a href="/tags/Scheme/" style="font-size: 10px;">Scheme</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/信息检索/" style="font-size: 14px;">信息检索</a> <a href="/tags/健身/" style="font-size: 10px;">健身</a> <a href="/tags/多线程/" style="font-size: 18px;">多线程</a> <a href="/tags/排序算法/" style="font-size: 19px;">排序算法</a> <a href="/tags/操作系统/" style="font-size: 13px;">操作系统</a> <a href="/tags/数据库/" style="font-size: 18px;">数据库</a> <a href="/tags/数据结构/" style="font-size: 13px;">数据结构</a> <a href="/tags/框架/" style="font-size: 10px;">框架</a> <a href="/tags/王道学习记录/" style="font-size: 13px;">王道学习记录</a> <a href="/tags/编程题/" style="font-size: 16px;">编程题</a> <a href="/tags/网络/" style="font-size: 11px;">网络</a> <a href="/tags/面经/" style="font-size: 14px;">面经</a> <a href="/tags/面试笔记/" style="font-size: 19px;">面试笔记</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">September 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">June 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">April 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/05/22/kafka/kafka详解--性能/">kafka详解--性能</a>
          </li>
        
          <li>
            <a href="/2017/05/22/kafka/Kafka设计解析（一）--Kafka背景及架构介绍/">Kafka设计解析（一）--Kafka背景及架构介绍</a>
          </li>
        
          <li>
            <a href="/2017/04/26/FreeMarker/2017-04-28/">Freemarker入门</a>
          </li>
        
          <li>
            <a href="/2017/04/26/FreeMarker/Freemarker/">Freemarker入门</a>
          </li>
        
          <li>
            <a href="/2017/04/20/Scala/2017-04-24/">Scala学习笔记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>